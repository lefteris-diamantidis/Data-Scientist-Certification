# Data-Scientist-Certification - DS601P
ğŸ½ï¸ Predicting High-Traffic Recipes for Homepage Optimization

ğŸ“Œ Project Overview

This project focuses on leveraging data science to help content teams make smarter, data-driven decisions about which recipes to feature on a websiteâ€™s homepage. The key objectives are:
	â€¢	ğŸ¯ Accurately predict which recipes will drive high user traffic.
	â€¢	ğŸ“ˆ Achieve a minimum precision rate of 80% in identifying high-traffic recipes.

â¸»

ğŸ“‚ Dataset Summary

The original dataset contained 947 recipes across 8 columns:
	â€¢	1 unique identifier: recipe_id
	â€¢	4 numeric variables: calories, carbohydrates, sugar, protein
	â€¢	2 categorical variables: category, servings
	â€¢	1 target variable: high_traffic (binary classification)

After comprehensive preprocessing, the dataset was refined to 895 clean observations ready for modeling.

â¸»

ğŸ§¹ Data Cleaning & Preprocessing

We applied rigorous cleaning steps to ensure high data quality:
	â€¢	âœ… Removed duplicates
	â€¢	âœ… Filled or removed missing values
	â€¢	âœ… Standardized data types
	â€¢	âœ… Extracted numeric servings from mixed-format strings (e.g., â€œ4 as a snackâ€)
	â€¢	âœ… Encoded categorical variables
	â€¢	âœ… Applied Yeo-Johnson transformation to correct skewed numeric distributions

ğŸ“Œ Why Yeo-Johnson?
It effectively normalized right-skewed features, improving model performance.

â¸»

ğŸ“Š Exploratory Data Analysis (EDA)

ğŸ” Key Insights:
	â€¢	Minimal correlation among numeric features â†’ less multicollinearity risk
	â€¢	All numeric features were right-skewed â†’ median used as the central tendency
	â€¢	Outliers detected using boxplots
	â€¢	Category medians for calories and nutrients varied widely

ğŸ“ˆ Categorical Analysis:
	â€¢	Recipes with serving size = 6 showed higher chances of being high traffic.
	â€¢	Categories like Vegetable, Potato, and Pork consistently performed well.
	â€¢	Beverages tended to attract the least traffic.

â¸»

ğŸ¤– Modeling Approach

Model Candidates:
	â€¢	Logistic Regression âœ… (Baseline - Best performing)
	â€¢	Random Forest
	â€¢	Support Vector Machine (SVM)

Preprocessing for Modeling:
	â€¢	Yeo-Johnson transformation for numeric features
	â€¢	One-hot encoding for the category column
	â€¢	Train-test split for model evaluation

â¸»

âœ… Model Evaluation
	â€¢	Logistic Regression achieved 80.35% precision, 82.56% recall, 81.44% f1-score, fulfilling the 80% objective.
	â€¢	Other models (e.g., Random Forest) showed signs of overfitting or underfitting due to data size.
	â€¢	Complex models like XGBoost and LGBM were intentionally excluded due to risk of overfitting on this dataset.

ğŸ’¡ From a business standpoint, false negatives (predicting low traffic for a high-traffic recipe) are costlier than false positives. Thus, model precision was prioritized over overall accuracy.

â¸»

ğŸ“Š Key Performance Indicator (KPI)

To align with business needs, we introduced a custom KPI:

High Traffic Conversion Rate

KPI = True Positives / False Positives

	â€¢	A strong model should maintain a KPI > 4.0
	â€¢	This metric was used to benchmark and compare model effectiveness

â¸»

ğŸ“Œ Business Recommendations
	â€¢	Consistently prioritize recipes in the â€œVegetable,â€ â€œPotato,â€ and â€œPorkâ€ categories on the homepage
	â€¢	Avoid featuring recipes from the â€œBeveragesâ€ category based on historical low traffic
	â€¢	Use the Logistic Regression model in production for daily content decisions
	â€¢	Monitor the High Traffic Conversion Rate KPI as a proxy for ROI

â¸»

ğŸ§  Lessons Learned
	â€¢	Simple models like Logistic Regression can outperform more complex ones when data is limited.
	â€¢	Skewed features and data imbalance must be addressed during preprocessing.
	â€¢	Business context should drive the choice of metricsâ€”precision over accuracy in this case.

â¸»

ğŸš€ Next Steps
	â€¢	Gather more labeled data, especially on low-traffic recipes
	â€¢	Consider adding new features: prep time, number of ingredients, or user ratings
	â€¢	Evaluate model stability over time and retrain periodically

â¸»

